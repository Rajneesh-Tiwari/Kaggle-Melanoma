{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "# from wtfml.utils import EarlyStopping\n",
    "# from wtfml.engine import Engine\n",
    "# from wtfml.data_loaders.image import ClassificationLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porting stuff from mtfml for our use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "class ClassificationLoader:\n",
    "    def __init__(self, image_paths, targets, resize, augmentations=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = Image.open(self.image_paths[item])\n",
    "        targets = self.targets[item]\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
    "            )\n",
    "        image = np.array(image)\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                \"EarlyStopping counter: {} out of {}\".format(\n",
    "                    self.counter, self.patience\n",
    "                )\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print(\n",
    "                \"Validation score improved ({} --> {}). Saving model!\".format(\n",
    "                    self.val_score, epoch_score\n",
    "                )\n",
    "            )\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from apex import amp\n",
    "    _apex_available = True\n",
    "except ImportError:\n",
    "    _apex_available = False\n",
    "\n",
    "class Engine:\n",
    "    \n",
    "    @staticmethod\n",
    "    def train(\n",
    "        data_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler=None,\n",
    "        accumulation_steps=1,\n",
    "        use_tpu=False,\n",
    "        fp16=False,\n",
    "    ):\n",
    "        if use_tpu and not _xla_available:\n",
    "            raise Exception(\n",
    "                \"You want to use TPUs but you dont have pytorch_xla installed\"\n",
    "            )\n",
    "        if fp16 and not _apex_available:\n",
    "            raise Exception(\"You want to use fp16 but you dont have apex installed\")\n",
    "        if fp16 and use_tpu:\n",
    "            raise Exception(\"Apex fp16 is not available when using TPUs\")\n",
    "        if fp16:\n",
    "            accumulation_steps = 1\n",
    "        losses = AverageMeter()\n",
    "        predictions = []\n",
    "        model.train()\n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "        for b_idx, data in enumerate(tk0):\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            if accumulation_steps == 1 and b_idx == 0:\n",
    "                optimizer.zero_grad()\n",
    "            _, loss = model(**data)\n",
    "\n",
    "            if not use_tpu:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    if fp16:\n",
    "                        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                            scaled_loss.backward()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                    if (b_idx + 1) % accumulation_steps == 0:\n",
    "                        optimizer.step()\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "                        if b_idx > 0:\n",
    "                            optimizer.zero_grad()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                xm.optimizer_step(optimizer)\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                if b_idx > 0:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            losses.update(loss.item(), data_loader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        return losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(data_loader, model, device, use_tpu=False):\n",
    "        losses = AverageMeter()\n",
    "        final_predictions = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, loss = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                losses.update(loss.item(), data_loader.batch_size)\n",
    "                final_predictions.append(predictions)\n",
    "                tk0.set_postfix(loss=losses.avg)\n",
    "        return final_predictions, losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(data_loader, model, device, use_tpu=False):\n",
    "        model.eval()\n",
    "        final_predictions = []\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, _ = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                final_predictions.append(predictions)\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, arch):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        self.arch.last_linear = nn.Linear(in_features=204800, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, image,targets):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        x = image\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        ### https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py\n",
    "        output = self.arch(x)\n",
    "        loss = criterion(output, targets.view(-1,1).float())\n",
    "        return output,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "import pretrainedmodels\n",
    "# arch = pretrainedmodels.__dict__['se_resnet152'](num_classes=1000, pretrained='imagenet')\n",
    "# arch\n",
    "# in_features  = arch.last_linear.in_features\n",
    "# arch.last_linear = nn.Linear(in_features=in_features, out_features=1, bias=True)\n",
    "# arch\n",
    "# arch._fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "\n",
    "def train(fold,bs,epochs,fp16,sz,arch='se_resnet152',debug=False):\n",
    "    if sz is not None:\n",
    "        sz = (sz,sz)\n",
    "    else:\n",
    "        sz = None\n",
    "    \n",
    "    _n = arch\n",
    "    import os\n",
    "    training_data_path = '../input/512x512-dataset-melanoma/512x512-dataset-melanoma/'\n",
    "    df = pd.read_csv('../input/folds_08062020.csv')\n",
    "    device = \"cuda\"\n",
    "    epochs = epochs\n",
    "    train_bs = bs\n",
    "    valid_bs = bs//2\n",
    "\n",
    "    df_train = df[df.fold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    arch = pretrainedmodels.__dict__[arch](num_classes=1000, pretrained='imagenet')\n",
    "    model = Net(arch=arch)  # New model for each fold\n",
    "    model = model.to(device)     \n",
    "#     if fold == 0:\n",
    "#         print(\"Loading existing model version for fold 0\")\n",
    "# #         model.load_state_dict(torch.load(bstModel))\n",
    "#         model.load_state_dict(torch.load('../models/model_arch_densenet121_sz_512_fold_0_epoch_3_auc_92.53.bin'))\n",
    "    \n",
    "\n",
    "    \n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "            albumentations.CoarseDropout(),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=30),\n",
    "            albumentations.Flip(p=0.5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    valid_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        train_images = df_train.image_id.values.tolist()[:250]\n",
    "        train_images = [os.path.join(training_data_path, i + \".jpg\") for i in train_images]\n",
    "        train_targets = df_train.target.values[:250]\n",
    "\n",
    "        valid_images = df_valid.image_id.values.tolist()[:250]\n",
    "        valid_images = [os.path.join(training_data_path, i + \".jpg\") for i in valid_images]\n",
    "        valid_targets = df_valid.target.values[:250]\n",
    "    else:\n",
    "        train_images = df_train.image_id.values.tolist()\n",
    "        train_images = [os.path.join(training_data_path, i + \".jpg\") for i in train_images]\n",
    "        train_targets = df_train.target.values\n",
    "\n",
    "        valid_images = df_valid.image_id.values.tolist()\n",
    "        valid_images = [os.path.join(training_data_path, i + \".jpg\") for i in valid_images]\n",
    "        valid_targets = df_valid.target.values\n",
    "        \n",
    "    train_dataset = ClassificationLoader(\n",
    "        image_paths=train_images,\n",
    "        targets=train_targets,\n",
    "        resize=sz,\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=train_bs, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = ClassificationLoader(\n",
    "        image_paths=valid_images,\n",
    "        targets=valid_targets,\n",
    "        resize=sz,\n",
    "        augmentations=valid_aug,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model, optimizer, device=device,fp16=fp16)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "        auc = metrics.roc_auc_score(valid_targets, predictions)\n",
    "        print(f\"Epoch = {epoch}, AUC = {auc}\")\n",
    "        scheduler.step(auc)\n",
    "        \n",
    "        if sz is not None:\n",
    "            ss = sz[0]\n",
    "        else:\n",
    "            ss = 512\n",
    "            \n",
    "        es(auc, model, model_path= \"../models/model_arch_{}_sz_{}_fold_{}_epoch_{}_auc_{}.bin\".format(_n,ss,fold,epoch,round(auc*100,2)))\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5831 [00:01<1:00:27,  1.61it/s, loss=1.65] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1010/5831 [06:06<27:40,  2.90it/s, loss=0.275]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1687/5831 [10:10<22:46,  3.03it/s, loss=0.264]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:17<00:00,  2.75it/s, loss=0.231]\n",
      "100%|██████████| 2953/2953 [02:30<00:00, 19.66it/s, loss=0.203] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.8860144358847052\n",
      "Validation score improved (-inf --> 0.8860144358847052). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1933/5831 [11:40<23:12,  2.80it/s, loss=0.217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4713/5831 [28:30<06:15,  2.98it/s, loss=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:16<00:00,  2.76it/s, loss=0.211]\n",
      " 70%|██████▉   | 2062/2953 [01:45<00:45, 19.78it/s, loss=0.11]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 98%|█████████▊| 5739/5831 [34:19<00:32,  2.81it/s, loss=0.2]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 53%|█████▎    | 3102/5831 [18:49<15:39,  2.90it/s, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4321/5831 [26:12<09:03,  2.78it/s, loss=0.193]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 44%|████▎     | 2542/5831 [15:25<19:19,  2.84it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2868/5831 [17:24<18:35,  2.66it/s, loss=0.182]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5831/5831 [35:22<00:00,  2.75it/s, loss=0.186]\n",
      "100%|██████████| 2953/2953 [02:28<00:00, 19.88it/s, loss=0.186] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9124353348174961\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1258/5831 [07:36<25:56,  2.94it/s, loss=0.176]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1503/5831 [09:05<24:52,  2.90it/s, loss=0.174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 3177/5831 [19:14<15:01,  2.95it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:22<00:00,  2.75it/s, loss=0.182]\n",
      "100%|██████████| 2953/2953 [02:27<00:00, 20.07it/s, loss=0.182] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9160406578720239\n",
      "Validation score improved (0.9127985453781855 --> 0.9160406578720239). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3428/5831 [20:50<13:07,  3.05it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4730/5831 [28:44<06:22,  2.88it/s, loss=0.179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 5143/5831 [31:12<03:39,  3.13it/s, loss=0.179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:20<00:00,  2.75it/s, loss=0.176]\n",
      "100%|██████████| 2953/2953 [02:27<00:00, 20.03it/s, loss=0.188] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9110349454472331\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3939/5831 [23:59<10:57,  2.88it/s, loss=0.173]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:27<00:00,  2.74it/s, loss=0.172]\n",
      "100%|██████████| 2953/2953 [02:29<00:00, 19.72it/s, loss=0.189] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9177776532077668\n",
      "Validation score improved (0.9160406578720239 --> 0.9177776532077668). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2210/5831 [13:26<20:18,  2.97it/s, loss=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 4483/5831 [27:16<07:49,  2.87it/s, loss=0.169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:26<00:00,  2.74it/s, loss=0.168]\n",
      "100%|██████████| 2953/2953 [02:30<00:00, 19.64it/s, loss=0.175] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9230276118327274\n",
      "Validation score improved (0.9177776532077668 --> 0.9230276118327274). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 922/5831 [05:36<27:34,  2.97it/s, loss=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2448/5831 [14:51<18:30,  3.05it/s, loss=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4684/5831 [28:28<06:17,  3.04it/s, loss=0.164]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 5162/5831 [31:22<03:37,  3.08it/s, loss=0.165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:26<00:00,  2.74it/s, loss=0.165]\n",
      "100%|██████████| 2953/2953 [02:28<00:00, 19.84it/s, loss=0.184] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.9114190659740574\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 4629/5831 [28:13<06:36,  3.03it/s, loss=0.161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:32<00:00,  2.73it/s, loss=0.162]\n",
      "100%|██████████| 2953/2953 [02:32<00:00, 19.32it/s, loss=0.173] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9238955978737678\n",
      "Validation score improved (0.9230276118327274 --> 0.9238955978737678). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 69/5831 [00:26<33:50,  2.84it/s, loss=0.185]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 2645/5831 [16:10<17:13,  3.08it/s, loss=0.163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:37<00:00,  2.73it/s, loss=0.161]\n",
      "100%|██████████| 2953/2953 [02:33<00:00, 19.22it/s, loss=0.177] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9252340581528403\n",
      "Validation score improved (0.9238955978737678 --> 0.9252340581528403). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2816/5831 [17:10<17:20,  2.90it/s, loss=0.15] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3037/5831 [18:31<16:43,  2.78it/s, loss=0.151]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:36<00:00,  2.73it/s, loss=0.154]\n",
      "100%|██████████| 2953/2953 [02:31<00:00, 19.46it/s, loss=0.184] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, AUC = 0.9233273361770887\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2658/5831 [16:12<17:14,  3.07it/s, loss=0.151]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 5189/5831 [31:40<03:44,  2.87it/s, loss=0.15] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [35:33<00:00,  2.73it/s, loss=0.151]\n",
      "100%|██████████| 2953/2953 [02:21<00:00, 20.81it/s, loss=0.185] \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, AUC = 0.9223950631125064\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1369/5831 [08:10<23:36,  3.15it/s, loss=0.153]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3505/5831 [20:53<13:13,  2.93it/s, loss=0.147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4538/5831 [27:03<07:12,  2.99it/s, loss=0.148]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [34:39<00:00,  2.80it/s, loss=0.148]\n",
      " 72%|███████▏  | 2133/2953 [01:39<00:41, 19.89it/s, loss=0.0998]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 89%|████████▊ | 5174/5831 [30:38<03:35,  3.06it/s, loss=0.145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5831/5831 [34:34<00:00,  2.81it/s, loss=0.145]\n",
      " 10%|▉         | 286/2953 [00:14<02:16, 19.55it/s, loss=0.048] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 63%|██████▎   | 3694/5831 [22:04<11:24,  3.12it/s, loss=0.143]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4425/5831 [26:27<08:19,  2.81it/s, loss=0.143]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 30%|███       | 1762/5831 [10:30<23:52,  2.84it/s, loss=0.135]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3215/5831 [19:10<15:35,  2.80it/s, loss=0.134]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 35%|███▌      | 2055/5831 [12:16<23:16,  2.70it/s, loss=0.137]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2953/2953 [02:23<00:00, 20.55it/s, loss=0.18]  \n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, AUC = 0.9218033555601823\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 381/5831 [02:17<32:14,  2.82it/s, loss=0.131]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5831/5831 [34:46<00:00,  2.79it/s, loss=0.133]\n",
      " 59%|█████▉    | 1742/2953 [01:24<00:57, 21.24it/s, loss=0.0738]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 98%|█████████▊| 5707/5831 [34:01<00:43,  2.83it/s, loss=0.132]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 75%|███████▌  | 4388/5831 [26:09<08:32,  2.82it/s, loss=0.126]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 46%|████▌     | 2666/5831 [15:55<18:47,  2.81it/s, loss=0.128]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2953/2953 [02:24<00:00, 20.44it/s, loss=0.182]\n",
      "  0%|          | 0/5831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 22, AUC = 0.9280901370803993\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1324/5831 [07:54<26:53,  2.79it/s, loss=0.126]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 98%|█████████▊| 2905/2953 [02:21<00:02, 21.04it/s, loss=0.183] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5831/5831 [34:46<00:00,  2.79it/s, loss=0.102]\n",
      " 31%|███       | 920/2953 [00:45<01:39, 20.52it/s, loss=0.0645]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 90%|████████▉ | 5234/5846 [33:50<03:54,  2.61it/s, loss=0.23] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 2540/5846 [16:24<20:39,  2.67it/s, loss=0.202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3069/5846 [19:50<17:23,  2.66it/s, loss=0.203]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 23%|██▎       | 1369/5846 [08:52<29:19,  2.55it/s, loss=0.198]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1601/5846 [10:22<27:30,  2.57it/s, loss=0.198]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 98%|█████████▊| 2877/2923 [02:38<00:02, 17.10it/s, loss=0.194] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5846/5846 [37:49<00:00,  2.58it/s, loss=0.19] \n",
      "100%|██████████| 2923/2923 [02:40<00:00, 18.21it/s, loss=0.189] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.907318993842418\n",
      "Validation score improved (0.8972234404260233 --> 0.907318993842418). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1701/5846 [10:53<25:25,  2.72it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 2266/5846 [14:30<20:42,  2.88it/s, loss=0.181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2680/5846 [17:09<20:14,  2.61it/s, loss=0.183]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2923/2923 [02:37<00:00, 18.50it/s, loss=0.187]\n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.907588665293234\n",
      "Validation score improved (0.907318993842418 --> 0.907588665293234). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1318/5846 [08:28<27:55,  2.70it/s, loss=0.18] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3099/5846 [19:55<15:35,  2.94it/s, loss=0.181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:34<00:00,  2.59it/s, loss=0.178]\n",
      "100%|██████████| 2923/2923 [02:34<00:00, 18.89it/s, loss=0.192] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9038951679101492\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 185/5846 [01:10<31:46,  2.97it/s, loss=0.181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 194/5846 [01:13<31:39,  2.98it/s, loss=0.249]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 4370/5846 [27:39<09:12,  2.67it/s, loss=0.175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:00<00:00,  2.63it/s, loss=0.176]\n",
      "100%|██████████| 2923/2923 [02:34<00:00, 18.89it/s, loss=0.188] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9053523632264541\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1952/5846 [12:28<22:10,  2.93it/s, loss=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:26<00:00,  2.60it/s, loss=0.169]\n",
      "100%|██████████| 2923/2923 [02:33<00:00, 18.98it/s, loss=0.186] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9117074085337271\n",
      "Validation score improved (0.907588665293234 --> 0.9117074085337271). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 853/5846 [05:26<28:14,  2.95it/s, loss=0.158] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 3196/5846 [20:29<16:53,  2.61it/s, loss=0.162]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:25<00:00,  2.60it/s, loss=0.165]\n",
      "100%|██████████| 2923/2923 [02:35<00:00, 18.74it/s, loss=0.182] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9108930894690028\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 194/5846 [01:14<35:12,  2.68it/s, loss=0.181] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2507/5846 [16:01<20:42,  2.69it/s, loss=0.164]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 3593/5846 [22:56<14:44,  2.55it/s, loss=0.162]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:17<00:00,  2.61it/s, loss=0.159]\n",
      "100%|██████████| 2923/2923 [02:24<00:00, 20.25it/s, loss=0.195] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.9094436682999998\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1647/5846 [10:02<22:41,  3.08it/s, loss=0.155]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3349/5846 [20:24<13:39,  3.05it/s, loss=0.156]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3565/5846 [21:43<12:26,  3.05it/s, loss=0.156]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [36:00<00:00,  2.71it/s, loss=0.156]\n",
      "100%|██████████| 2923/2923 [02:33<00:00, 18.99it/s, loss=0.184] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9176088552110796\n",
      "Validation score improved (0.9117074085337271 --> 0.9176088552110796). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:04<00:00,  2.63it/s, loss=0.155]\n",
      "100%|██████████| 2923/2923 [02:35<00:00, 18.78it/s, loss=0.174] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9216993371396167\n",
      "Validation score improved (0.9176088552110796 --> 0.9216993371396167). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 640/5846 [04:04<29:12,  2.97it/s, loss=0.153] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2562/5846 [16:19<18:28,  2.96it/s, loss=0.152]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4774/5846 [30:25<06:14,  2.86it/s, loss=0.151]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:15<00:00,  2.62it/s, loss=0.151]\n",
      "100%|██████████| 2923/2923 [02:35<00:00, 18.81it/s, loss=0.19]  \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, AUC = 0.9158773239555775\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3449/5846 [21:59<13:37,  2.93it/s, loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 5776/5846 [36:48<00:27,  2.55it/s, loss=0.147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:15<00:00,  2.61it/s, loss=0.148]\n",
      "100%|██████████| 2923/2923 [02:36<00:00, 18.74it/s, loss=0.176] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, AUC = 0.9236015337935324\n",
      "Validation score improved (0.9216993371396167 --> 0.9236015337935324). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 2074/5846 [13:13<21:54,  2.87it/s, loss=0.14] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 5192/5846 [33:05<03:56,  2.77it/s, loss=0.143]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:15<00:00,  2.62it/s, loss=0.144]\n",
      "100%|██████████| 2923/2923 [02:35<00:00, 18.78it/s, loss=0.182] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, AUC = 0.9174813134650518\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 459/5846 [02:55<30:59,  2.90it/s, loss=0.138]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2013/5846 [12:49<22:06,  2.89it/s, loss=0.145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 2038/5846 [12:58<21:32,  2.95it/s, loss=0.146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2236/5846 [14:14<20:23,  2.95it/s, loss=0.214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:14<00:00,  2.62it/s, loss=0.18] \n",
      "100%|██████████| 2923/2923 [02:36<00:00, 18.71it/s, loss=0.178] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, AUC = 0.9206333186234272\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [37:17<00:00,  2.61it/s, loss=0.137]\n",
      "100%|██████████| 2923/2923 [02:36<00:00, 18.63it/s, loss=0.19]  \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, AUC = 0.9203491506744073\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 842/5846 [05:22<29:14,  2.85it/s, loss=0.133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3112/5846 [19:44<16:31,  2.76it/s, loss=0.133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 5499/5846 [34:48<01:56,  2.97it/s, loss=0.135]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [36:59<00:00,  2.63it/s, loss=0.135]\n",
      "100%|██████████| 2923/2923 [02:33<00:00, 19.03it/s, loss=0.218] \n",
      "  0%|          | 0/5846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, AUC = 0.8979741486737076\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1736/5846 [10:54<22:59,  2.98it/s, loss=0.109]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3761/5846 [23:41<11:46,  2.95it/s, loss=0.113]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5846/5846 [36:50<00:00,  2.65it/s, loss=0.114]\n",
      "100%|██████████| 2923/2923 [02:33<00:00, 19.08it/s, loss=0.188] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, AUC = 0.923330124592143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/5850 [00:02<55:19,  1.76it/s, loss=1.19]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 39/5850 [00:16<34:36,  2.80it/s, loss=0.574]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 161/5850 [01:05<34:46,  2.73it/s, loss=0.366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [39:27<00:00,  2.47it/s, loss=0.231]\n",
      "100%|██████████| 2915/2915 [02:50<00:00, 17.07it/s, loss=0.211] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.8754629824589819\n",
      "Validation score improved (-inf --> 0.8754629824589819). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 711/5850 [04:46<30:28,  2.81it/s, loss=0.225] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 2844/5850 [19:18<17:58,  2.79it/s, loss=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 4192/5850 [28:26<10:58,  2.52it/s, loss=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [40:22<00:00,  2.41it/s, loss=0.211]\n",
      "100%|██████████| 2915/2915 [03:09<00:00, 15.41it/s, loss=0.198] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.8981074858799547\n",
      "Validation score improved (0.8754629824589819 --> 0.8981074858799547). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1842/5850 [13:10<27:33,  2.42it/s, loss=0.205]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1845/5850 [13:11<26:17,  2.54it/s, loss=0.206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [42:02<00:00,  2.32it/s, loss=0.203]\n",
      "100%|██████████| 2915/2915 [03:04<00:00, 15.76it/s, loss=0.197] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.8970320717652313\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1539/5850 [10:51<32:10,  2.23it/s, loss=0.198]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4576/5850 [31:43<08:09,  2.60it/s, loss=0.194]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [40:26<00:00,  2.41it/s, loss=0.194]\n",
      "100%|██████████| 2915/2915 [02:55<00:00, 16.58it/s, loss=0.194] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.904991543012631\n",
      "Validation score improved (0.8981074858799547 --> 0.904991543012631). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1311/5850 [08:43<26:24,  2.87it/s, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1315/5850 [08:45<25:35,  2.95it/s, loss=0.204]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1338/5850 [08:54<26:11,  2.87it/s, loss=0.253]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [39:22<00:00,  2.48it/s, loss=0.228]\n",
      "100%|██████████| 2915/2915 [02:50<00:00, 17.06it/s, loss=0.189] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9097027444138764\n",
      "Validation score improved (0.904991543012631 --> 0.9097027444138764). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4837/5850 [32:16<05:59,  2.81it/s, loss=0.183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [38:59<00:00,  2.50it/s, loss=0.185]\n",
      "100%|██████████| 2915/2915 [02:49<00:00, 17.19it/s, loss=0.184] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9134988789574884\n",
      "Validation score improved (0.9097027444138764 --> 0.9134988789574884). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1044/5850 [07:06<31:43,  2.52it/s, loss=0.185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2764/5850 [18:55<19:16,  2.67it/s, loss=0.18] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 3810/5850 [26:01<12:36,  2.70it/s, loss=0.178]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4983/5850 [33:59<05:14,  2.76it/s, loss=0.181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 5015/5850 [34:12<05:06,  2.73it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [39:53<00:00,  2.44it/s, loss=0.183]\n",
      "100%|██████████| 2915/2915 [02:49<00:00, 17.17it/s, loss=0.181] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9213666306483073\n",
      "Validation score improved (0.9134988789574884 --> 0.9213666306483073). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 4359/5850 [29:48<08:59,  2.76it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 4360/5850 [29:49<08:23,  2.96it/s, loss=0.186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 4378/5850 [29:56<09:06,  2.69it/s, loss=0.194]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [39:54<00:00,  2.44it/s, loss=0.191]\n",
      "100%|██████████| 2915/2915 [02:48<00:00, 17.33it/s, loss=0.184] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9146572664147694\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 4764/5850 [31:23<07:02,  2.57it/s, loss=0.172]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 2753/5850 [17:52<19:12,  2.69it/s, loss=0.166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3276/5850 [21:16<16:34,  2.59it/s, loss=0.167]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 33%|███▎      | 1921/5850 [12:29<22:38,  2.89it/s, loss=0.172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2011/5850 [13:05<24:54,  2.57it/s, loss=0.171]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2915/2915 [02:41<00:00, 18.07it/s, loss=0.18] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9155608104824994\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 851/5850 [05:31<32:58,  2.53it/s, loss=0.17]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 71%|███████   | 2063/2915 [01:54<00:46, 18.36it/s, loss=0.103] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 96%|█████████▌| 5614/5850 [36:32<01:21,  2.89it/s, loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 5827/5850 [37:55<00:07,  2.90it/s, loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5850/5850 [38:04<00:00,  2.56it/s, loss=0.144]\n",
      " 13%|█▎        | 371/2915 [00:20<02:25, 17.45it/s, loss=0.0748]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 68%|██████▊   | 3978/5850 [25:53<10:43,  2.91it/s, loss=0.138]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4439/5850 [28:53<08:45,  2.69it/s, loss=0.138]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4879/5850 [31:43<06:25,  2.52it/s, loss=0.138]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 61%|██████    | 3566/5850 [23:03<14:35,  2.61it/s, loss=0.134]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  8%|▊         | 494/5850 [03:12<33:15,  2.68it/s, loss=0.141]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1913/5850 [12:20<25:23,  2.58it/s, loss=0.137]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2915/2915 [02:42<00:00, 17.99it/s, loss=0.169] \n",
      "  0%|          | 0/5850 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, AUC = 0.9291640886930889\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 595/5850 [03:52<32:30,  2.69it/s, loss=0.134] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 693/5850 [04:31<33:35,  2.56it/s, loss=0.132]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5850/5850 [38:00<00:00,  2.57it/s, loss=0.13]\n",
      " 67%|██████▋   | 1943/2915 [01:47<00:58, 16.48it/s, loss=0.0986]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5850/5850 [38:01<00:00,  2.56it/s, loss=0.129]\n",
      " 10%|▉         | 277/2915 [00:15<02:31, 17.40it/s, loss=0.0783]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 59%|█████▊    | 3425/5851 [23:42<14:23,  2.81it/s, loss=0.236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 4365/5851 [30:06<09:53,  2.50it/s, loss=0.231]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 3067/5851 [21:02<20:05,  2.31it/s, loss=0.21] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 26%|██▌       | 1500/5851 [10:31<26:55,  2.69it/s, loss=0.206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1792/5851 [12:34<28:27,  2.38it/s, loss=0.207]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 92%|█████████▏| 5367/5851 [37:43<02:59,  2.70it/s, loss=0.199]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [41:07<00:00,  2.37it/s, loss=0.199]\n",
      "100%|██████████| 2913/2913 [03:01<00:00, 16.08it/s, loss=0.196] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.8975670874120443\n",
      "Validation score improved (0.8917900126104717 --> 0.8975670874120443). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 906/5851 [06:24<34:47,  2.37it/s, loss=0.188]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 94%|█████████▍| 5511/5851 [38:51<02:19,  2.43it/s, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 5513/5851 [38:52<02:14,  2.51it/s, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [41:16<00:00,  2.36it/s, loss=0.193]\n",
      "100%|██████████| 2913/2913 [03:02<00:00, 15.95it/s, loss=0.184] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.9091645692561605\n",
      "Validation score improved (0.8975670874120443 --> 0.9091645692561605). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1989/5851 [14:15<24:23,  2.64it/s, loss=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 2051/5851 [14:42<24:06,  2.63it/s, loss=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [41:40<00:00,  2.34it/s, loss=0.2]  \n",
      "100%|██████████| 2913/2913 [03:06<00:00, 15.65it/s, loss=0.191] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9064725363693582\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 106/5851 [00:46<36:37,  2.61it/s, loss=0.202] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2440/5851 [17:16<20:57,  2.71it/s, loss=0.187]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4775/5851 [33:49<06:41,  2.68it/s, loss=0.186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [41:27<00:00,  2.35it/s, loss=0.191]\n",
      "100%|██████████| 2913/2913 [03:03<00:00, 15.85it/s, loss=0.183] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9128659693380505\n",
      "Validation score improved (0.9091645692561605 --> 0.9128659693380505). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4537/5851 [32:08<08:16,  2.64it/s, loss=0.18] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4710/5851 [33:21<07:12,  2.64it/s, loss=0.18] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4728/5851 [33:28<06:59,  2.67it/s, loss=0.182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 4889/5851 [34:37<06:00,  2.67it/s, loss=0.183]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 5068/5851 [35:53<05:09,  2.53it/s, loss=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 5071/5851 [35:55<04:49,  2.70it/s, loss=0.192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [41:30<00:00,  2.35it/s, loss=0.207]\n",
      "100%|██████████| 2913/2913 [03:06<00:00, 15.60it/s, loss=0.33] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.8354957189789457\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [40:57<00:00,  2.38it/s, loss=0.199]\n",
      "100%|██████████| 2913/2913 [03:00<00:00, 16.15it/s, loss=0.189] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9035894329151888\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [40:51<00:00,  2.39it/s, loss=0.182]\n",
      "100%|██████████| 2913/2913 [02:59<00:00, 16.24it/s, loss=0.2]   \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.8923652678480531\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 5519/5851 [38:35<02:01,  2.73it/s, loss=0.175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [40:55<00:00,  2.38it/s, loss=0.175]\n",
      "100%|██████████| 2913/2913 [03:00<00:00, 16.17it/s, loss=0.2]   \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.9050323082959366\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 63/5851 [00:26<38:19,  2.52it/s, loss=0.196] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2406/5851 [16:38<23:03,  2.49it/s, loss=0.158]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 5277/5851 [36:43<04:28,  2.14it/s, loss=0.159]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [40:52<00:00,  2.39it/s, loss=0.159]\n",
      "100%|██████████| 2913/2913 [03:08<00:00, 15.47it/s, loss=0.181] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9149129881170269\n",
      "Validation score improved (0.9128659693380505 --> 0.9149129881170269). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 3428/5851 [24:40<14:43,  2.74it/s, loss=0.15]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 4080/5851 [29:25<11:36,  2.54it/s, loss=0.149]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [42:17<00:00,  2.31it/s, loss=0.152]\n",
      "100%|██████████| 2913/2913 [03:10<00:00, 15.27it/s, loss=0.18]  \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9175421358438353\n",
      "Validation score improved (0.9149129881170269 --> 0.9175421358438353). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 84/5851 [00:37<39:54,  2.41it/s, loss=0.145]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4286/5851 [30:52<10:25,  2.50it/s, loss=0.15]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [42:05<00:00,  2.32it/s, loss=0.149]\n",
      "100%|██████████| 2913/2913 [03:11<00:00, 15.24it/s, loss=0.18]  \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, AUC = 0.9163150856761539\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1009/5851 [07:16<32:55,  2.45it/s, loss=0.14]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3251/5851 [23:40<17:01,  2.54it/s, loss=0.147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 5336/5851 [38:52<03:20,  2.57it/s, loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [42:33<00:00,  2.29it/s, loss=0.145]\n",
      "100%|██████████| 2913/2913 [03:10<00:00, 15.27it/s, loss=0.177] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, AUC = 0.9191589904043005\n",
      "Validation score improved (0.9175421358438353 --> 0.9191589904043005). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2622/5851 [19:17<21:43,  2.48it/s, loss=0.144] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4918/5851 [36:20<06:25,  2.42it/s, loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [43:05<00:00,  2.26it/s, loss=0.144]\n",
      "100%|██████████| 2913/2913 [03:09<00:00, 15.34it/s, loss=0.18]  \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, AUC = 0.9192580554310856\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2086/5851 [15:15<25:11,  2.49it/s, loss=0.142]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 4108/5851 [30:10<11:20,  2.56it/s, loss=0.141]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5851/5851 [44:34<00:00,  2.19it/s, loss=0.141]  \n",
      "100%|██████████| 2913/2913 [03:02<00:00, 15.92it/s, loss=0.181] \n",
      "  0%|          | 0/5851 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, AUC = 0.9166438162244828\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5852/5852 [44:15<00:00,  2.20it/s, loss=0.179]\n",
      "100%|██████████| 2912/2912 [03:21<00:00, 14.48it/s, loss=0.18]  \n",
      "  0%|          | 0/5852 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9167735022844141\n",
      "Validation score improved (0.9074943029278484 --> 0.9167735022844141). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1007/5852 [07:34<31:23,  2.57it/s, loss=0.171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1419/5852 [10:39<29:22,  2.51it/s, loss=0.174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 5431/5852 [40:49<02:59,  2.34it/s, loss=0.174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5852/5852 [43:49<00:00,  2.23it/s, loss=0.175]\n",
      "100%|██████████| 2912/2912 [03:14<00:00, 14.97it/s, loss=0.188] \n",
      "  0%|          | 0/5852 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.906174760480937\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1667/5852 [12:28<28:22,  2.46it/s, loss=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1710/5852 [12:47<27:07,  2.54it/s, loss=0.179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2010/5852 [15:02<25:24,  2.52it/s, loss=0.175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2095/5852 [15:41<24:48,  2.52it/s, loss=0.175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2392/5852 [17:54<22:59,  2.51it/s, loss=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2886/5852 [21:37<19:27,  2.54it/s, loss=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5852/5852 [43:52<00:00,  2.22it/s, loss=0.198]\n",
      "100%|██████████| 2912/2912 [03:22<00:00, 14.38it/s, loss=0.19]  \n",
      "  0%|          | 0/5852 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9054058884639873\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2960/5852 [22:14<21:33,  2.24it/s, loss=0.187]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 27%|██▋       | 1594/5852 [12:00<32:28,  2.19it/s, loss=0.17] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5852/5852 [44:01<00:00,  2.22it/s, loss=0.168]\n",
      "100%|██████████| 2912/2912 [03:22<00:00, 14.40it/s, loss=0.181] \n",
      "  0%|          | 0/5852 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9143240870721144\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5852/5852 [42:37<00:00,  2.29it/s, loss=0.153]\n",
      "  0%|          | 0/2912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2912/2912 [03:15<00:00, 14.92it/s, loss=0.177] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9167267248537565\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "e = 30\n",
    "debug= False\n",
    "bs = 8\n",
    "mtype = 'se_resnet152'\n",
    "train(0,bs,e,True,None,mtype,debug=debug)\n",
    "train(1,bs,e,True,None,mtype,debug=debug)\n",
    "train(2,bs,e,True,None,mtype,debug=debug)\n",
    "train(3,bs,e,True,None,mtype,debug=debug)\n",
    "train(4,bs,e,True,None,mtype,debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink, FileLinks\n",
    "# FileLinks('../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
