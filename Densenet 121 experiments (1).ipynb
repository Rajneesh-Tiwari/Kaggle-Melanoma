{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "# from wtfml.utils import EarlyStopping\n",
    "# from wtfml.engine import Engine\n",
    "# from wtfml.data_loaders.image import ClassificationLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porting stuff from mtfml for our use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "class ClassificationLoader:\n",
    "    def __init__(self, image_paths, targets, resize, augmentations=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = Image.open(self.image_paths[item])\n",
    "        targets = self.targets[item]\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
    "            )\n",
    "        image = np.array(image)\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                \"EarlyStopping counter: {} out of {}\".format(\n",
    "                    self.counter, self.patience\n",
    "                )\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print(\n",
    "                \"Validation score improved ({} --> {}). Saving model!\".format(\n",
    "                    self.val_score, epoch_score\n",
    "                )\n",
    "            )\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from apex import amp\n",
    "    _apex_available = True\n",
    "except ImportError:\n",
    "    _apex_available = False\n",
    "\n",
    "class Engine:\n",
    "    \n",
    "    @staticmethod\n",
    "    def train(\n",
    "        data_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler=None,\n",
    "        accumulation_steps=1,\n",
    "        use_tpu=False,\n",
    "        fp16=False,\n",
    "    ):\n",
    "        if use_tpu and not _xla_available:\n",
    "            raise Exception(\n",
    "                \"You want to use TPUs but you dont have pytorch_xla installed\"\n",
    "            )\n",
    "        if fp16 and not _apex_available:\n",
    "            raise Exception(\"You want to use fp16 but you dont have apex installed\")\n",
    "        if fp16 and use_tpu:\n",
    "            raise Exception(\"Apex fp16 is not available when using TPUs\")\n",
    "        if fp16:\n",
    "            accumulation_steps = 1\n",
    "        losses = AverageMeter()\n",
    "        predictions = []\n",
    "        model.train()\n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "        for b_idx, data in enumerate(tk0):\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            if accumulation_steps == 1 and b_idx == 0:\n",
    "                optimizer.zero_grad()\n",
    "            _, loss = model(**data)\n",
    "\n",
    "            if not use_tpu:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    if fp16:\n",
    "                        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                            scaled_loss.backward()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                    if (b_idx + 1) % accumulation_steps == 0:\n",
    "                        optimizer.step()\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "                        if b_idx > 0:\n",
    "                            optimizer.zero_grad()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                xm.optimizer_step(optimizer)\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                if b_idx > 0:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            losses.update(loss.item(), data_loader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        return losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(data_loader, model, device, use_tpu=False):\n",
    "        losses = AverageMeter()\n",
    "        final_predictions = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, loss = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                losses.update(loss.item(), data_loader.batch_size)\n",
    "                final_predictions.append(predictions)\n",
    "                tk0.set_postfix(loss=losses.avg)\n",
    "        return final_predictions, losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(data_loader, model, device, use_tpu=False):\n",
    "        model.eval()\n",
    "        final_predictions = []\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, _ = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                final_predictions.append(predictions)\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, arch):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        self.arch.last_linear = nn.Linear(in_features=102400, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, image,targets):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        x = image\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        ### https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py\n",
    "        output = self.arch(x)\n",
    "        loss = criterion(output, targets.view(-1,1).float())\n",
    "        return output,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "# import pretrainedmodels\n",
    "# arch = pretrainedmodels.__dict__['densenet121'](num_classes=1000, pretrained='imagenet')\n",
    "# # arch\n",
    "# in_features  = arch.last_linear.in_features\n",
    "# arch.last_linear = nn.Linear(in_features=in_features, out_features=1, bias=True)\n",
    "# arch\n",
    "# arch._fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arch.last_linear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "\n",
    "def train(fold,bs,epochs,fp16,sz,arch='densenet121',debug=False):\n",
    "    if sz is not None:\n",
    "        sz = (sz,sz)\n",
    "    else:\n",
    "        sz = None\n",
    "    \n",
    "    _n = arch\n",
    "    import os\n",
    "    training_data_path = '../input/512x512-dataset-melanoma/512x512-dataset-melanoma/'\n",
    "    df = pd.read_csv('../input/folds_08062020.csv')\n",
    "    device = \"cuda\"\n",
    "    epochs = epochs\n",
    "    train_bs = bs\n",
    "    valid_bs = bs//2\n",
    "\n",
    "    df_train = df[df.fold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    arch = pretrainedmodels.__dict__[arch](num_classes=1000, pretrained='imagenet')\n",
    "    model = Net(arch=arch)  # New model for each fold\n",
    "    \n",
    "    if fold == 0:\n",
    "        print(\"Loading existing model version for fold 0\")\n",
    "#         model.load_state_dict(torch.load(bstModel))\n",
    "        model.load_state_dict(torch.load('../models/model_arch_densenet121_sz_512_fold_0_epoch_3_auc_92.53.bin'))\n",
    "    \n",
    "    model = model.to(device) \n",
    "    \n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "            albumentations.CoarseDropout(),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=30),\n",
    "            albumentations.Flip(p=0.5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    valid_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        train_images = df_train.image_id.values.tolist()[:250]\n",
    "        train_images = [os.path.join(training_data_path, i + \".jpg\") for i in train_images]\n",
    "        train_targets = df_train.target.values[:250]\n",
    "\n",
    "        valid_images = df_valid.image_id.values.tolist()[:250]\n",
    "        valid_images = [os.path.join(training_data_path, i + \".jpg\") for i in valid_images]\n",
    "        valid_targets = df_valid.target.values[:250]\n",
    "    else:\n",
    "        train_images = df_train.image_id.values.tolist()\n",
    "        train_images = [os.path.join(training_data_path, i + \".jpg\") for i in train_images]\n",
    "        train_targets = df_train.target.values\n",
    "\n",
    "        valid_images = df_valid.image_id.values.tolist()\n",
    "        valid_images = [os.path.join(training_data_path, i + \".jpg\") for i in valid_images]\n",
    "        valid_targets = df_valid.target.values\n",
    "        \n",
    "    train_dataset = ClassificationLoader(\n",
    "        image_paths=train_images,\n",
    "        targets=train_targets,\n",
    "        resize=sz,\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=train_bs, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = ClassificationLoader(\n",
    "        image_paths=valid_images,\n",
    "        targets=valid_targets,\n",
    "        resize=sz,\n",
    "        augmentations=valid_aug,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model, optimizer, device=device,fp16=fp16)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "        auc = metrics.roc_auc_score(valid_targets, predictions)\n",
    "        print(f\"Epoch = {epoch}, AUC = {auc}\")\n",
    "        scheduler.step(auc)\n",
    "        \n",
    "        if sz is not None:\n",
    "            ss = sz[0]\n",
    "        else:\n",
    "            ss = 512\n",
    "            \n",
    "        es(auc, model, model_path= \"../models/model_arch_{}_sz_{}_fold_{}_epoch_{}_auc_{}.bin\".format(_n,ss,fold,epoch,round(auc*100,2)))\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model version for fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 800/1944 [05:00<06:48,  2.80it/s, loss=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1135/1944 [07:05<04:46,  2.83it/s, loss=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1441/1944 [08:59<02:58,  2.83it/s, loss=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:07<00:00,  2.67it/s, loss=0.174]\n",
      "100%|██████████| 985/985 [01:01<00:00, 16.11it/s, loss=0.188] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.9161747041017345\n",
      "Validation score improved (-inf --> 0.9161747041017345). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:05<00:00,  2.68it/s, loss=0.16] \n",
      "100%|██████████| 985/985 [01:00<00:00, 16.33it/s, loss=0.181] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.9169732868509235\n",
      "Validation score improved (0.9161747041017345 --> 0.9169732868509235). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:05<00:00,  2.68it/s, loss=0.156]\n",
      "100%|██████████| 985/985 [01:01<00:00, 15.93it/s, loss=0.177] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.9199644797511448\n",
      "Validation score improved (0.9169732868509235 --> 0.9199644797511448). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1061/1944 [06:38<05:32,  2.66it/s, loss=0.15] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 985/985 [01:01<00:00, 15.94it/s, loss=0.177] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9215712994253763\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 109/1944 [00:41<10:48,  2.83it/s, loss=0.133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 989/1944 [06:11<05:55,  2.69it/s, loss=0.141]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1944/1944 [12:16<00:00,  2.64it/s, loss=0.13] \n",
      "100%|██████████| 985/985 [01:05<00:00, 15.04it/s, loss=0.176] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9270992271320604\n",
      "Validation score improved (0.9218048681960305 --> 0.9270992271320604). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1518/1944 [09:56<02:30,  2.82it/s, loss=0.124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1623/1944 [10:35<01:53,  2.84it/s, loss=0.124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:42<00:00,  2.55it/s, loss=0.127]\n",
      "100%|██████████| 985/985 [01:09<00:00, 14.23it/s, loss=0.181] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9230203600785147\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:30<00:00,  2.59it/s, loss=0.121]\n",
      "100%|██████████| 985/985 [01:07<00:00, 14.57it/s, loss=0.207] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9130184559369177\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1810/1944 [11:29<00:47,  2.83it/s, loss=0.116]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:19<00:00,  2.63it/s, loss=0.115]\n",
      "100%|██████████| 985/985 [01:10<00:00, 13.97it/s, loss=0.198] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.9167433662020206\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 972/1944 [06:37<05:52,  2.75it/s, loss=0.111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 973/1944 [06:37<05:38,  2.87it/s, loss=0.111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 975/1944 [06:38<05:36,  2.88it/s, loss=0.115]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:55<00:00,  2.51it/s, loss=0.117]\n",
      "100%|██████████| 985/985 [01:05<00:00, 15.14it/s, loss=0.185] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9241548369645491\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:27<00:00,  2.60it/s, loss=0.0837]\n",
      "100%|██████████| 985/985 [01:04<00:00, 15.23it/s, loss=0.2]   \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9284472970976967\n",
      "Validation score improved (0.9270992271320604 --> 0.9284472970976967). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:27<00:00,  2.60it/s, loss=0.0718]\n",
      "100%|██████████| 985/985 [01:08<00:00, 14.39it/s, loss=0.218] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, AUC = 0.9214574513331661\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:42<00:00,  2.55it/s, loss=0.0674]\n",
      "100%|██████████| 985/985 [01:00<00:00, 16.30it/s, loss=0.217] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, AUC = 0.9223687254530345\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1217/1944 [08:28<04:47,  2.53it/s, loss=0.0646]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [13:29<00:00,  2.40it/s, loss=0.0639]\n",
      "100%|██████████| 985/985 [01:08<00:00, 14.46it/s, loss=0.222] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, AUC = 0.9211526552097848\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1867/1944 [12:17<00:28,  2.74it/s, loss=0.0582]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:47<00:00,  2.53it/s, loss=0.0584]\n",
      "100%|██████████| 985/985 [01:07<00:00, 14.55it/s, loss=0.239] \n",
      "  0%|          | 0/1944 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, AUC = 0.9177268464389883\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [12:12<00:00,  2.66it/s, loss=0.0556]\n",
      "100%|██████████| 985/985 [01:00<00:00, 16.24it/s, loss=0.237] \n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, AUC = 0.919035409915417\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1949 [00:08<11:51,  2.71it/s, loss=0.802]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 846/1949 [05:26<06:37,  2.78it/s, loss=0.23] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:31<00:00,  2.59it/s, loss=0.218]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.11it/s, loss=0.2]   \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.8938271898515366\n",
      "Validation score improved (-inf --> 0.8938271898515366). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:32<00:00,  2.59it/s, loss=0.191]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.10it/s, loss=0.196] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.897883282610833\n",
      "Validation score improved (0.8938271898515366 --> 0.897883282610833). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:30<00:00,  2.60it/s, loss=0.179]\n",
      "100%|██████████| 975/975 [00:59<00:00, 16.32it/s, loss=0.197] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.9029935497442535\n",
      "Validation score improved (0.897883282610833 --> 0.9029935497442535). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 237/1949 [01:31<10:22,  2.75it/s, loss=0.177]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1549/1949 [09:57<02:28,  2.69it/s, loss=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:31<00:00,  2.59it/s, loss=0.173]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.11it/s, loss=0.188] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.9146931841306789\n",
      "Validation score improved (0.9029935497442535 --> 0.9146931841306789). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:33<00:00,  2.59it/s, loss=0.161]\n",
      "100%|██████████| 975/975 [01:01<00:00, 15.97it/s, loss=0.19]  \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.913702437652482\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1934/1949 [12:26<00:05,  2.71it/s, loss=0.154]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:32<00:00,  2.59it/s, loss=0.154]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.23it/s, loss=0.175] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9244325901400947\n",
      "Validation score improved (0.9146931841306789 --> 0.9244325901400947). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1194/1949 [07:39<04:30,  2.79it/s, loss=0.148]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1469/1949 [09:25<02:53,  2.77it/s, loss=0.151]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:30<00:00,  2.60it/s, loss=0.151]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.07it/s, loss=0.186] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.9147705597614708\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:31<00:00,  2.59it/s, loss=0.143]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.10it/s, loss=0.183] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9222527649669484\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:30<00:00,  2.60it/s, loss=0.136]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.20it/s, loss=0.183] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.925911964641349\n",
      "Validation score improved (0.9244325901400947 --> 0.925911964641349). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1634/1949 [10:29<01:52,  2.79it/s, loss=0.127]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:30<00:00,  2.60it/s, loss=0.13] \n",
      "100%|██████████| 975/975 [01:00<00:00, 16.03it/s, loss=0.184] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.9177695971391138\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:31<00:00,  2.59it/s, loss=0.125]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.14it/s, loss=0.196] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.9209114044454403\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 383/1949 [02:28<09:43,  2.68it/s, loss=0.121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 936/1949 [06:00<06:00,  2.81it/s, loss=0.119]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [12:29<00:00,  2.60it/s, loss=0.123]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.22it/s, loss=0.197] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9223362227247471\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1601/1949 [10:18<02:14,  2.59it/s, loss=0.114]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1949/1949 [12:36<00:00,  2.58it/s, loss=0.0734]\n",
      "100%|██████████| 975/975 [01:00<00:00, 16.15it/s, loss=0.198] \n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, AUC = 0.9308042355383712\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 104/1949 [00:41<11:53,  2.58it/s, loss=0.0722]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 975/975 [01:03<00:00, 15.25it/s, loss=0.207]\n",
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, AUC = 0.9307746937786243\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1949 [00:01<28:43,  1.13it/s, loss=0.0974]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1258/1949 [08:15<04:31,  2.55it/s, loss=0.0603]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1950/1950 [13:04<00:00,  2.48it/s, loss=0.217]\n",
      "  7%|▋         | 67/972 [00:04<00:58, 15.49it/s, loss=0.105] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1950/1950 [12:48<00:00,  2.54it/s, loss=0.182]\n",
      "100%|██████████| 972/972 [01:01<00:00, 15.72it/s, loss=0.183] \n",
      "  0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.9245767688523718\n",
      "Validation score improved (0.9162564815693206 --> 0.9245767688523718). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 493/1950 [03:18<09:36,  2.53it/s, loss=0.177]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 80%|███████▉  | 1553/1950 [10:12<02:34,  2.57it/s, loss=0.156]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1950/1950 [13:05<00:00,  2.48it/s, loss=0.119]\n",
      " 55%|█████▍    | 531/972 [00:33<00:28, 15.39it/s, loss=0.0671]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 972/972 [01:02<00:00, 15.65it/s, loss=0.176] \n",
      "  0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.9292517822146432\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 771/1950 [05:10<07:20,  2.68it/s, loss=0.0911]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 835/1950 [05:36<07:30,  2.48it/s, loss=0.0936]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 62%|██████▏   | 1200/1950 [07:52<04:39,  2.68it/s, loss=0.0889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1890/1950 [12:23<00:23,  2.58it/s, loss=0.0876]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1950/1950 [13:20<00:00,  2.43it/s, loss=0.0815]\n",
      "100%|██████████| 972/972 [00:58<00:00, 16.67it/s, loss=0.192] \n",
      "  0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, AUC = 0.9283210739795507\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 243/1950 [01:36<11:17,  2.52it/s, loss=0.0704]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.25it/s, loss=0.195]\n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.899188214819422\n",
      "Validation score improved (-inf --> 0.899188214819422). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1328/1951 [09:25<04:31,  2.30it/s, loss=0.203]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1951/1951 [13:49<00:00,  2.35it/s, loss=0.174]\n",
      " 14%|█▍        | 135/971 [00:08<00:51, 16.23it/s, loss=0.0439]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1951/1951 [13:09<00:00,  2.47it/s, loss=0.157]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.19it/s, loss=0.2]   \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9178813162895043\n",
      "Validation score improved (0.9110233505510485 --> 0.9178813162895043). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 65/1951 [00:28<12:18,  2.55it/s, loss=0.163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 395/1951 [02:49<10:09,  2.55it/s, loss=0.149]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 505/1951 [03:37<10:11,  2.36it/s, loss=0.148]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 80%|████████  | 1566/1951 [10:35<02:42,  2.37it/s, loss=0.138]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1951/1951 [13:37<00:00,  2.39it/s, loss=0.128]\n",
      " 94%|█████████▍| 911/971 [00:55<00:03, 16.34it/s, loss=0.172] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 971/971 [01:00<00:00, 16.06it/s, loss=0.182] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, AUC = 0.9268783063475184\n",
      "Validation score improved (0.9249681580017046 --> 0.9268783063475184). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 985/1951 [07:04<07:01,  2.29it/s, loss=0.0825]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 24%|██▍       | 475/1951 [03:10<09:02,  2.72it/s, loss=0.0654]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1415/1951 [09:27<03:32,  2.52it/s, loss=0.0698]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 64%|██████▍   | 1254/1951 [08:31<04:22,  2.65it/s, loss=0.0665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:11<00:00,  2.46it/s, loss=0.066] \n",
      " 79%|███████▊  | 763/971 [00:46<00:12, 16.79it/s, loss=0.135] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1951/1951 [13:09<00:00,  2.47it/s, loss=0.0628]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.33it/s, loss=0.215] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, AUC = 0.9260806772945374\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:08<00:00,  2.47it/s, loss=0.0559]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.37it/s, loss=0.214] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 19, AUC = 0.9250901199146621\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1460/1951 [09:49<03:03,  2.68it/s, loss=0.0548]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1574/1951 [10:34<02:20,  2.68it/s, loss=0.055] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:06<00:00,  2.48it/s, loss=0.0553]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.37it/s, loss=0.217] \n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 20, AUC = 0.9256919411134815\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1951 [00:01<22:14,  1.46it/s, loss=0.779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1951 [00:03<14:24,  2.25it/s, loss=1.15] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:26<00:00,  2.42it/s, loss=0.22] \n",
      "100%|██████████| 971/971 [00:59<00:00, 16.35it/s, loss=0.187] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.9048244054379112\n",
      "Validation score improved (-inf --> 0.9048244054379112). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1229/1951 [08:29<04:34,  2.63it/s, loss=0.189]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1335/1951 [09:12<03:59,  2.57it/s, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1443/1951 [09:57<03:16,  2.59it/s, loss=0.199]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:27<00:00,  2.41it/s, loss=0.202]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.27it/s, loss=0.211] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.9060846964726559\n",
      "Validation score improved (0.9048244054379112 --> 0.9060846964726559). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:28<00:00,  2.41it/s, loss=0.183]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.36it/s, loss=0.184] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.9139062086915725\n",
      "Validation score improved (0.9060846964726559 --> 0.9139062086915725). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:25<00:00,  2.42it/s, loss=0.174]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.30it/s, loss=0.176] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.9130595604690217\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:29<00:00,  2.41it/s, loss=0.163]\n",
      "100%|██████████| 971/971 [01:00<00:00, 16.05it/s, loss=0.178] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9189497000659073\n",
      "Validation score improved (0.9139062086915725 --> 0.9189497000659073). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 430/1951 [03:00<09:52,  2.57it/s, loss=0.153]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 578/1951 [04:01<08:53,  2.57it/s, loss=0.155]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 581/1951 [04:02<08:35,  2.66it/s, loss=0.158]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:33<00:00,  2.40it/s, loss=0.162]\n",
      "100%|██████████| 971/971 [01:01<00:00, 15.74it/s, loss=0.184] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9195252253694719\n",
      "Validation score improved (0.9189497000659073 --> 0.9195252253694719). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 495/1951 [03:28<10:05,  2.40it/s, loss=0.147]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1951/1951 [13:37<00:00,  2.39it/s, loss=0.143]\n",
      "100%|██████████| 971/971 [01:01<00:00, 15.77it/s, loss=0.204] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.9268594610495273\n",
      "Validation score improved (0.9220477157719533 --> 0.9268594610495273). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 154/1951 [01:05<12:00,  2.49it/s, loss=0.131]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 191/1951 [01:20<11:22,  2.58it/s, loss=0.174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:32<00:00,  2.40it/s, loss=0.149]\n",
      "100%|██████████| 971/971 [01:00<00:00, 16.09it/s, loss=0.19]  \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9151495109082175\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:33<00:00,  2.40it/s, loss=0.131]\n",
      "100%|██████████| 971/971 [01:00<00:00, 15.97it/s, loss=0.177] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, AUC = 0.920222558171575\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:34<00:00,  2.40it/s, loss=0.126]\n",
      "100%|██████████| 971/971 [01:00<00:00, 16.10it/s, loss=0.184] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, AUC = 0.91366817905935\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1636/1951 [11:22<02:01,  2.60it/s, loss=0.12] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:34<00:00,  2.40it/s, loss=0.12] \n",
      "100%|██████████| 971/971 [01:00<00:00, 15.95it/s, loss=0.188] \n",
      "  0%|          | 0/1951 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, AUC = 0.9247642045137195\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1841/1951 [12:47<00:42,  2.60it/s, loss=0.0904]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [13:33<00:00,  2.40it/s, loss=0.0907]\n",
      "100%|██████████| 971/971 [00:59<00:00, 16.19it/s, loss=0.188] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, AUC = 0.9257231185698487\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "e = 30\n",
    "debug= False\n",
    "bs = 24\n",
    "mtype = 'densenet121'\n",
    "train(0,bs,e,True,None,mtype,debug=debug)\n",
    "train(1,bs,e,True,None,mtype,debug=debug)\n",
    "train(2,bs,e,True,None,mtype,debug=debug)\n",
    "train(3,bs,e,True,None,mtype,debug=debug)\n",
    "train(4,bs,e,True,None,mtype,debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink, FileLinks\n",
    "# FileLinks('../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
