{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet_pytorch\n",
    "# !pip install pretrainedmodels\n",
    "# !pip install albumentations\n",
    "# !pip install pandas\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import albumentations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['head/neck','lower extremity','oral/genital','palms/soles','torso','unknown_anatomy','upper extremity','female','male','unknown_sex','age__0.0','age__10.0','age__15.0','age__20.0','age__25.0','age__30.0','age__35.0','age__40.0','age__45.0','age__50.0','age__55.0','age__60.0','age__65.0','age__70.0','age__75.0','age__80.0','age__85.0','age__90.0','n_images','image_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "class ClassificationLoader:\n",
    "    def __init__(self, image_paths, targets, resize,augmentations=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "#         self.tabularDF = tabularDF\n",
    "#         self.cols = cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = Image.open(self.image_paths[item])\n",
    "        targets = self.targets[item]\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
    "            )\n",
    "        image = np.array(image)\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "#         tabFeats = self.tabularDF.loc[item,cols].values.astype(float)\n",
    "#         print(tabFeats)\n",
    "        \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long)\n",
    "#             \"tabfeats\":torch.tensor(np.array(tabFeats),dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                \"EarlyStopping counter: {} out of {}\".format(\n",
    "                    self.counter, self.patience\n",
    "                )\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print(\n",
    "                \"Validation score improved ({} --> {}). Saving model!\".format(\n",
    "                    self.val_score, epoch_score\n",
    "                )\n",
    "            )\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "        \n",
    "    @staticmethod\n",
    "    def train(\n",
    "        data_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler=None,\n",
    "        accumulation_steps=1,\n",
    "        use_tpu=False,\n",
    "        fp16=False,\n",
    "    ):\n",
    "\n",
    "        try:\n",
    "            from apex import amp\n",
    "            _apex_available = True\n",
    "        except ImportError:\n",
    "            _apex_available = False\n",
    "\n",
    "        if use_tpu and not _xla_available:\n",
    "            raise Exception(\n",
    "                \"You want to use TPUs but you dont have pytorch_xla installed\"\n",
    "            )\n",
    "        if fp16 and not _apex_available:\n",
    "            raise Exception(\"You want to use fp16 but you dont have apex installed\")\n",
    "        if fp16 and use_tpu:\n",
    "            raise Exception(\"Apex fp16 is not available when using TPUs\")\n",
    "        if fp16:\n",
    "            accumulation_steps = 1\n",
    "        losses = AverageMeter()\n",
    "        predictions = []\n",
    "        model.train()\n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "        for b_idx, data in enumerate(tk0):\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            if accumulation_steps == 1 and b_idx == 0:\n",
    "                optimizer.zero_grad()\n",
    "            _, loss = model(**data)\n",
    "\n",
    "            if not use_tpu:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    if fp16:\n",
    "                        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                            scaled_loss.backward()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                    if (b_idx + 1) % accumulation_steps == 0:\n",
    "                        optimizer.step()\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "                        if b_idx > 0:\n",
    "                            optimizer.zero_grad()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                xm.optimizer_step(optimizer)\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                if b_idx > 0:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            losses.update(loss.item(), data_loader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        return losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(data_loader, model, device, use_tpu=False):\n",
    "        losses = AverageMeter()\n",
    "        final_predictions = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, loss = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                losses.update(loss.item(), data_loader.batch_size)\n",
    "                final_predictions.append(predictions)\n",
    "                tk0.set_postfix(loss=losses.avg)\n",
    "        return final_predictions, losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(data_loader, model, device, use_tpu=False):\n",
    "        model.eval()\n",
    "        final_predictions = []\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                for key, value in data.items():\n",
    "                    data[key] = value.to(device)\n",
    "                predictions, _ = model(**data)\n",
    "                predictions = predictions.cpu()\n",
    "                final_predictions.append(predictions)\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.05):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        x = x.float()\n",
    "        target = target.float()\n",
    "        \n",
    "        target = target* (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        loss = F.binary_cross_entropy_with_logits(x, target.type_as(x))\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "# y_smo = y.float() * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "#         loss  = F.binary_cross_entropy_with_logits(y_hat, y_smo.type_as(y_hat),\n",
    "#                                                    pos_weight=torch.tensor(pos_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelSmoothing(nn.Module):\n",
    "#     def __init__(self, smoothing = 0.05):\n",
    "#         super(LabelSmoothing, self).__init__()\n",
    "#         self.confidence = 1.0 - smoothing\n",
    "#         self.smoothing = smoothing\n",
    "\n",
    "#     def forward(self, x, target):\n",
    "#         x = x.float()\n",
    "#         target = target.float()\n",
    "#         logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "\n",
    "#         nll_loss = -logprobs * target\n",
    "#         nll_loss = nll_loss.sum(-1)\n",
    "\n",
    "# #         smooth_loss = -logprobs.mean(dim=-1)\n",
    "#         smooth_loss = -logprobs * (1-target)\n",
    "#         smooth_loss = smooth_loss .sum(-1)\n",
    "#         loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "\n",
    "#         return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, arch):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        \n",
    "        in_features  = arch._fc.in_features\n",
    "        self.arch._fc = nn.Linear(in_features=in_features, out_features=1, bias=True)\n",
    "                                \n",
    "    def forward(self, image,targets):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        x = image\n",
    "#         criterion = nn.BCEWithLogitsLoss()\n",
    "        criterion = LabelSmoothing()\n",
    "        ### https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py\n",
    "        output = self.arch(x)\n",
    "        loss = criterion(output, targets.view(-1,1).float())\n",
    "        return output,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC_2637011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0015719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>ISIC_0052212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0068279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0074268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  source  stratify_group  fold  \\\n",
       "0   unknown           benign       0  ISIC20              20     0   \n",
       "1   unknown           benign       0  ISIC20               2     1   \n",
       "2     nevus           benign       0  ISIC20               0     4   \n",
       "3   unknown           benign       0  ISIC20               2     3   \n",
       "4   unknown           benign       0  ISIC20               1     3   \n",
       "\n",
       "       image_id  \n",
       "0  ISIC_2637011  \n",
       "1  ISIC_0015719  \n",
       "2  ISIC_0052212  \n",
       "3  ISIC_0068279  \n",
       "4  ISIC_0074268  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds = pd.read_csv('../input/FinalFolds_combinedExternal.csv')\n",
    "df_folds['image_id']=df_folds['image_name']\n",
    "df_folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Microscope(A.ImageOnlyTransform):\n",
    "    def __init__(self, p: float = 0.5, always_apply=False):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        if random.random() < self.p:\n",
    "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8),\n",
    "                        (img.shape[0]//2, img.shape[1]//2),\n",
    "                        random.randint(img.shape[0]//2 - 3, img.shape[0]//2 + 15),\n",
    "                        (0, 0, 0),\n",
    "                        -1)\n",
    "\n",
    "            mask = circle - 255\n",
    "            img = np.multiply(img, mask)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "\n",
    "def train(fold,bs,epochs,fp16,sz,arch='se_resnet152',debug=False,accumulation_steps=1):\n",
    "    if sz is not None:\n",
    "        sz = (sz,sz)\n",
    "    else:\n",
    "        sz = None\n",
    "    \n",
    "    _n = arch\n",
    "    import os\n",
    "#     training_data_path = '../input/128X128/train/'\n",
    "    training_data_path = '../input/384X384/train/'\n",
    "    df = df_folds\n",
    "    device = \"cuda\"\n",
    "    epochs = epochs\n",
    "    train_bs = bs\n",
    "    valid_bs = bs//2\n",
    "\n",
    "    df_train = df[df.fold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    arch = EfficientNet.from_pretrained(arch)\n",
    "#     arch = pretrainedmodels.__dict__[arch](num_classes=1000, pretrained='imagenet')\n",
    "    model = Net(arch=arch)  # New model for each fold\n",
    "    model = model.to(device)     \n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "            albumentations.CoarseDropout(),\n",
    "            albumentations.RandomBrightness(0.3),\n",
    "            albumentations.RandomContrast(0.3),\n",
    "            albumentations.ChannelShuffle(),\n",
    "            albumentations.Cutout(4,4,4),\n",
    "            Microscope(),\n",
    "            albumentations.ChannelDropout(p=0.1),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=30),\n",
    "            albumentations.Flip(p=0.5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    valid_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        train_images = df_train.image_id.values.tolist()[:250]\n",
    "        train_images = [os.path.join(training_data_path, i + \".jpg\") for i in train_images]\n",
    "        train_targets = df_train.target.values[:250]\n",
    "\n",
    "        valid_images = df_valid.image_id.values.tolist()[:250]\n",
    "        valid_images = [os.path.join(training_data_path, i + \".jpg\") for i in valid_images]\n",
    "        valid_targets = df_valid.target.values[:250]\n",
    "    else:\n",
    "        train_images = df_train.image_id.values.tolist()\n",
    "        train_images = [os.path.join(training_data_path, i + \".jpg\") for i in train_images]\n",
    "        train_targets = df_train.target.values\n",
    "\n",
    "        valid_images = df_valid.image_id.values.tolist()\n",
    "        valid_images = [os.path.join(training_data_path, i + \".jpg\") for i in valid_images]\n",
    "        valid_targets = df_valid.target.values\n",
    "        \n",
    "    train_dataset = ClassificationLoader(\n",
    "        image_paths=train_images,\n",
    "        targets=train_targets,\n",
    "        resize=sz,\n",
    "#         tabularDF = df_train,\n",
    "#         cols = cols,\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=train_bs, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = ClassificationLoader(\n",
    "        image_paths=valid_images,\n",
    "        targets=valid_targets,\n",
    "        resize=sz,\n",
    "#         tabularDF = df_valid,\n",
    "#         cols = cols,\n",
    "        augmentations=valid_aug)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=2,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    if fp16:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
    "    es = EarlyStopping(patience=3, mode=\"max\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model, optimizer, device=device,fp16=fp16,accumulation_steps=accumulation_steps)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "        auc = metrics.roc_auc_score(valid_targets, predictions)\n",
    "        print(f\"Epoch = {epoch}, AUC = {auc}\")\n",
    "        scheduler.step(auc)\n",
    "        \n",
    "        if sz is not None:\n",
    "            ss = sz[0]\n",
    "        else:\n",
    "            ss = 384\n",
    "            \n",
    "        es(auc, model, model_path= \"../models/model_arch_{}_sz_{}_fold_{}_epoch_{}_auc_{}.bin\".format(_n,ss,fold,epoch,round(auc*100,2)))\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 284/3341 [02:26<24:28,  2.08it/s, loss=0.365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [28:49<00:00,  1.93it/s, loss=0.286]\n",
      "100%|██████████| 1671/1671 [01:42<00:00, 16.33it/s, loss=0.283]\n",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.9066865999285747\n",
      "Validation score improved (-inf --> 0.9066865999285747). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1358/3341 [11:48<16:18,  2.03it/s, loss=0.265]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1753/3341 [15:14<13:36,  1.94it/s, loss=0.264]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [29:01<00:00,  1.92it/s, loss=0.263]\n",
      "100%|██████████| 1671/1671 [01:41<00:00, 16.39it/s, loss=0.257]\n",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.9105796298106755\n",
      "Validation score improved (0.9066865999285747 --> 0.9105796298106755). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 2957/3341 [25:38<03:13,  1.98it/s, loss=0.251]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [28:58<00:00,  1.92it/s, loss=0.252]\n",
      "100%|██████████| 1671/1671 [01:42<00:00, 16.32it/s, loss=0.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.9162162392681101\n",
      "Validation score improved (0.9105796298106755 --> 0.9162162392681101). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 3108/3341 [26:41<01:49,  2.13it/s, loss=0.243]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [28:38<00:00,  1.94it/s, loss=0.243]\n",
      "100%|██████████| 1671/1671 [01:36<00:00, 17.24it/s, loss=0.247]\n",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.9160102544838375\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 179/3341 [01:29<24:25,  2.16it/s, loss=0.217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [27:52<00:00,  2.00it/s, loss=0.236]\n",
      "100%|██████████| 1671/1671 [01:37<00:00, 17.18it/s, loss=0.235]\n",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9319396374704483\n",
      "Validation score improved (0.9162162392681101 --> 0.9319396374704483). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 890/3341 [07:25<19:06,  2.14it/s, loss=0.232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1767/3341 [14:44<12:12,  2.15it/s, loss=0.231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [27:52<00:00,  2.00it/s, loss=0.228]\n",
      "100%|██████████| 1671/1671 [01:37<00:00, 17.20it/s, loss=0.244]\n",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9348223697641483\n",
      "Validation score improved (0.9319396374704483 --> 0.9348223697641483). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2058/3341 [17:30<10:15,  2.09it/s, loss=0.221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3341/3341 [28:33<00:00,  1.95it/s, loss=0.22] \n",
      " 23%|██▎       | 381/1671 [00:23<01:15, 17.10it/s, loss=0.166]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3341/3341 [28:49<00:00,  1.93it/s, loss=0.215]\n",
      " 94%|█████████▍| 1577/1671 [01:36<00:05, 16.23it/s, loss=0.225]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1671/1671 [01:42<00:00, 16.32it/s, loss=0.222]\n",
      "  0%|          | 0/3341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9318910760531409\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 478/3341 [04:09<22:54,  2.08it/s, loss=0.202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 961/3341 [08:21<20:46,  1.91it/s, loss=0.205]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 58%|█████▊    | 1949/3336 [17:46<12:33,  1.84it/s, loss=0.295]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 87%|████████▋ | 2915/3336 [25:17<03:37,  1.94it/s, loss=0.265]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 76%|███████▌  | 2520/3336 [21:53<06:33,  2.07it/s, loss=0.256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3336/3336 [29:03<00:00,  1.91it/s, loss=0.254]\n",
      " 18%|█▊        | 301/1681 [00:20<01:34, 14.54it/s, loss=0.166]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3336/3336 [30:10<00:00,  1.84it/s, loss=0.246]\n",
      " 91%|█████████▏| 1535/1681 [01:43<00:09, 14.89it/s, loss=0.246]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1681/1681 [01:52<00:00, 14.97it/s, loss=0.234]\n",
      "  0%|          | 0/3336 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9388427108251423\n",
      "Validation score improved (0.9233435615970853 --> 0.9388427108251423). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 743/3336 [06:46<23:33,  1.83it/s, loss=0.227]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1681/1681 [01:52<00:00, 14.97it/s, loss=0.23] \n",
      "  0%|          | 0/3336 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.9392879422043265\n",
      "Validation score improved (0.9388427108251423 --> 0.9392879422043265). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 722/3336 [06:33<23:41,  1.84it/s, loss=0.22] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 53%|█████▎    | 1784/3336 [16:13<13:58,  1.85it/s, loss=0.22] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 24%|██▎       | 785/3336 [07:08<21:20,  1.99it/s, loss=0.21] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 989/3336 [08:59<19:41,  1.99it/s, loss=0.213]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1602/3336 [14:33<15:36,  1.85it/s, loss=0.215]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 78%|███████▊  | 2615/3336 [23:45<06:34,  1.83it/s, loss=0.215]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 74%|███████▍  | 2482/3336 [22:34<07:42,  1.85it/s, loss=0.21] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3336/3336 [30:19<00:00,  1.83it/s, loss=0.209]\n",
      " 14%|█▍        | 233/1681 [00:15<01:36, 15.01it/s, loss=0.159]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3336/3336 [30:09<00:00,  1.84it/s, loss=0.205]\n",
      " 50%|████▉     | 833/1681 [00:46<00:46, 18.10it/s, loss=0.161]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3336/3336 [28:23<00:00,  1.96it/s, loss=0.199]\n",
      " 63%|██████▎   | 1063/1681 [01:09<00:40, 15.26it/s, loss=0.188]"
     ]
    }
   ],
   "source": [
    "e = 25\n",
    "debug= False\n",
    "bs = 14\n",
    "accumulation_steps = 1\n",
    "mtype = 'efficientnet-b6'\n",
    "from apex import amp, optimizers\n",
    "apx = True\n",
    "\n",
    "# train(0,bs,e,apx,None,mtype,debug=debug,accumulation_steps=accumulation_steps)\n",
    "# train(1,bs,e,apx,None,mtype,debug=debug,accumulation_steps=accumulation_steps)\n",
    "# train(2,bs,e,apx,None,mtype,debug=debug,accumulation_steps=accumulation_steps)\n",
    "train(3,bs,e,apx,None,mtype,debug=debug,accumulation_steps=accumulation_steps)\n",
    "train(4,bs,e,apx,None,mtype,debug=debug,accumulation_steps=accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
